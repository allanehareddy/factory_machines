# Factory Machine Event Ingestion System

This project implements a backend service for ingesting, deduplicating, updating, and analyzing factory machine events in a reliable and scalable manner. The system is built using Spring Boot with a layered architecture that separates controllers, services, repositories, validation, and utility components. Controllers expose REST APIs for event ingestion and statistics retrieval, services encapsulate all business logic, repositories handle persistence using Spring Data JPA, and utility components manage payload comparison and validation. This separation ensures clarity, testability, and long-term maintainability.

Event ingestion follows a strict deduplication and update strategy based on eventId and receivedTime. When an event arrives, it is first validated for correctness (invalid duration, future eventTime, etc.). If the eventId does not exist, the event is stored. If the eventId already exists and the payload is identical, the event is marked as deduplicated. If the payload differs, the system compares timestamps and updates the stored event only if the new event has a newer receivedTime; otherwise, the incoming event is ignored. Payload comparison is done field-by-field to ensure accurate detection of meaningful changes. This logic guarantees deterministic “winning” records and protects against stale updates.

Thread safety is achieved using transactional boundaries and database-level guarantees instead of manual locking. Each ingestion request runs inside a transaction, ensuring atomic read-modify-write behavior. The uniqueness of eventId combined with transactional semantics prevents race conditions during concurrent ingestion. This approach avoids JVM locks, keeps the system scalable, and relies on proven database consistency mechanisms.

The data model centers around an EventEntity that stores event identifiers, factory and line metadata, machine identifiers, event and received timestamps, duration, and defect counts. Derived statistics are calculated dynamically using repository queries instead of being stored redundantly. Special handling ensures that defectCount = -1 is excluded from defect aggregations, preserving correctness of metrics.

Performance is optimized to comfortably ingest batches of 1000 events within one second. The ingestion flow is a single pass over the input data, deduplication uses indexed lookups on eventId, and unnecessary synchronization is avoided. Batch ingestion via a single API call minimizes HTTP overhead, and database interaction is kept efficient through transactional writes and selective queries.

Several edge cases are explicitly handled. Duplicate events with identical payloads are deduplicated, older updates are ignored, invalid durations and future event times are rejected, defect counts marked as -1 are excluded from defect statistics, and eventTime boundaries are handled correctly using inclusive start and exclusive end semantics. These decisions were made to ensure predictable behavior and clean statistical results, even under imperfect or noisy input data.

The application can be run locally by setting up Java 17, configuring JAVA_HOME, and starting the service using Maven. All functionality is covered by unit and integration tests, including concurrency scenarios, ensuring correctness under load. With additional time, the system could be enhanced with asynchronous ingestion, bulk database operations, externalized clock injection for better testability, and migration to a production-grade database for higher throughput.
